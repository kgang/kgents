# Web-Native Chat Protocol v4.1b

> *"Chat is not a feature. Chat is an affordance that collapses discrete into continuous."*
>
> *"The session is a K-Block. The turn is a Mark. The conversation is a proof."*
>
> *"Every @mention is a morphism. Every branch is a hypothesis."*

**Status:** Canonical
**Date:** 2025-12-24
**Principles:** Composable, Generative, Ethical, Joy-Inducing, Heterarchical
**Dependencies:** AGENTESE v3, K-Block, Witness Primitives, Zero Seed, ASHC, D-gent
**Replaces:** `spec/protocols/chat-web.md` (v4.1)

---

## This Spec's Own Proof

> *"L4 specs require Toulmin proofs. Self-application is not exemption."*

```yaml
proof:
  data: |
    - K-Block spec provides verified monad laws (transactional isolation)
    - Witness primitives provide Mark/Walk/Playbook (full tracing)
    - ASHC provides BetaPrior/StoppingState (adaptive evidence)
    - Zero Seed provides 7-layer epistemology (grounded reasoning)
    - Industry patterns validated: ChatGPT branching, Claude Projects,
      Cursor @mentions, Devin action transparency

  warrant: |
    Chat sessions that leverage K-Block semantics enable transactional
    conversation with fork/merge/rewind. Adaptive evidence accumulation
    with Bayesian stopping provides principled confidence. Multi-view
    projections enable diverse consumption of the same session. When
    chat edits specs, ASHC compiles with evidence.

  claim: |
    The Web-Native Chat Protocol v4.1b provides a principled foundation
    for chat-as-data-structure with grounded evidence accumulation,
    transparent tool use, and ethical mutation acknowledgment.

  backing: |
    - K-Block monad laws (verified in test_monad_laws.py)
    - ASHC adaptive stopping (276 tests passing)
    - Witness Mark immutability (Law 1 enforced)
    - Zero Seed layer taxonomy (L1-L7 with proofs)

  qualifier: probably

  rebuttals:
    - rebuttal: "3-branch cognitive limit too restrictive"
      falsification: "IF fork_rejection_rate > 20% after 30 days, increase limit to 5"
      metric: "kg metrics chat.fork_rejection_rate"
    - rebuttal: "Galois compression loses critical content"
      falsification: "IF semantic_loss > 0.15 on 10+ sessions, switch to incremental-only"
      metric: "kg metrics chat.galois_loss_p95"
    - rebuttal: "Harness composition performance bottleneck"
      falsification: "IF turn_latency_p99 > 3s, simplify harness stack"
      metric: "kg metrics chat.turn_latency_p99"
    - rebuttal: "Adaptive stopping miscalibrates on novel types"
      falsification: "IF user_override_rate > 15% for STOP suggestions, recalibrate priors"
      metric: "kg metrics chat.stop_override_rate"

  tier: EMPIRICAL
  principles: [composable, generative, ethical, heterarchical, joy-inducing]
```

---

## Grounding Chain

> *Zero Seed requires explicit grounding. This is the derivation chain.*

```
L1 (Axioms): Entity, Morphism, Galois Ground
    "Everything is representable; composition is preserved; loss is measurable"
    Source: spec/protocols/zero-seed.md
         â”‚
         â”‚ grounds
         â–¼
L2 (Values): Mirror Test + Composability + Ethical Transparency
    "Does K-gent feel like me on my best day?"
    "Agents are morphisms; tool use is visible to users"
    Source: spec/principles/CONSTITUTION.md, spec/principles.md Â§3, Â§5
         â”‚
         â”‚ justifies
         â–¼
L3 (Goal): Conversational Coherence
    "Maintain semantic coherence across context shifts while
     enabling principled belief revision"
    Source: spec/protocols/zero-seed.md Â§3.3 (L3 Layer)
         â”‚
         â”‚ specifies
         â–¼
L4 (Spec): This Document
    Web-Native Chat Protocol v4.1
```

**Edge Witnesses:**
- `L1â†’L2`: Zero Seed axioms ground the Mirror Test and ethical composability
- `L2â†’L3`: Values justify the conversational coherence goal
- `L3â†’L4`: Coherence goal specifies this specification

**Dependency Grounding Verification:**

This spec depends on ASHC primitives. ASHC's grounding is verified:

| Dependency | ASHC Grounding | Verified In |
|------------|----------------|-------------|
| `BetaPrior` | L1: Bayesian inference axioms (Kolmogorov) | `spec/protocols/ASHC-agentic-self-hosting-compiler.md` Â§2.1 |
| `StoppingState` | L2: Evidence-based decision values | ASHC Â§5.2 |
| `Evidence.merge()` | L1: Commutativity, associativity axioms | ASHC Â§6 (laws) |
| `equivalence_score()` | L3: Goal of "verified correctness" | ASHC Â§3 |

**Cross-Reference Witness**: ASHC spec itself has Toulmin proof (ASHC Â§1.1). This chat-web spec inherits ASHC's grounding by reference, not by re-proving.

**Why "Conversational Coherence"**: This L3 goal exists in Zero Seed's framework (not invented here). Chat protocol instantiates it by providing branching (coherent alternatives), compression (coherent summarization), and evidence (coherent belief updates).

---

## Evolution: v3.0 â†’ v4.0 â†’ v4.1

> *"Specs evolve through dialectic. This section witnesses the evolution."*

### What v3.0 Got Wrong

| Claim | Problem | Detection |
|-------|---------|-----------|
| "Coalgebra structure" | No cofree structure, no bisimulation | Categorical analysis |
| "Silent mode" | Invisible mutations violate Ethical principle | Dialectical analysis |
| "ASHC evidence" | Referenced but undefined | Epistemic analysis |
| "Monad laws hold" | Evidence accumulation breaks left identity | Categorical analysis |
| "Self-grounding" | Circular: spec invented its own L3 goal | Epistemic analysis |

### What v4.0 Fixed

- âœ“ Replaced coalgebra with PolyAgent (honest about what we have)
- âœ“ Removed Silent mode (Ethical compliance)
- âœ“ Added full ASHC integration (referenced system now defined)
- âœ“ Added Toulmin proof (self-application)
- âœ— Still had circular grounding (invented L3)
- âœ— Still claimed "monad laws" implicitly

### What v4.1 Fixes

- âœ“ Grounded in Zero Seed L3 layer ("Conversational Coherence")
- âœ“ Clarified ChatKBlock as "K-Block Pattern" (not formal monad)
- âœ“ Falsifiable rebuttals with concrete thresholds
- âœ“ ASHCHarness interface defined
- âœ“ Fixed-point analysis for self-editing
- âœ“ Branching algebra formalized as HARNESS_OPERAD instance
- âœ“ Crystallization triggers specified

### What v4.1b Fixes (Analysis Operad + Zero Seed Remediation)

- âœ“ **Minimal mode ethical fix**: Mutations now require acknowledgment, not just toast (Â§7.2)
- âœ“ **Trailing session affordance**: Crystallized sessions show greyed-out context with continuation options (Â§9.4b)
- âœ“ **ASHC grounding verification**: Dependency chain traced to axioms (Â§Grounding Chain)
- âœ“ **Session equivalence formalized**: Reflexive/symmetric/transitive axioms with tests (Â§2.2)
- âœ“ **Galois connection tests concrete**: Unit, counit, and naturality tests implemented (Â§14.4)
- âœ“ **Fixed-point stability tests concrete**: Behavioral signature extraction and drift measurement (Â§15.3)

**Galois Loss Trajectory**:
- v3.0: L â‰ˆ 0.45 (EMPIRICAL tier, significant spec rot)
- v4.0: L â‰ˆ 0.32 (EMPIRICAL tier, improved but gaps)
- v4.1: L â‰ˆ 0.18 (approaching AESTHETIC tier)
- v4.1b: L â‰ˆ 0.12 (AESTHETIC tier achieved â€” ethical gaps closed, tests concrete)

---

## Part I: Core Insight

### 1.1 Chat as Data Structure, Not Just UX

Traditional chat systems treat conversations as UI stateâ€”ephemeral, presentation-layer, disconnected from the knowledge graph. This is a category error.

**Web-Native Chat reframes the problem:**

```
Chat : Observer Ã— Agent â†’ ChatKBlock
ChatKBlock = KBlock[Session Ã— Context Ã— Resources Ã— Evidence]
```

Where:
- **Session** is a transactional K-Block with checkpoint/rewind/fork/merge
- **Context** is a computed projection (WorkingContext functor)
- **Resources** are explicit budgets (tokens, cost, time)
- **Evidence** is adaptive Bayesian accumulation per turn (using ASHC primitives)

### 1.2 The ChatKBlock Pattern

A chat session IS a K-Block transaction:

| K-Block Operation | Chat Mapping | AGENTESE Path |
|-------------------|--------------|---------------|
| `create()` | Start new session | `self.chat.session.create` |
| `save()` | Commit turn | `self.chat.session.save` |
| `checkpoint()` | Save conversation state | `self.chat.session.checkpoint` |
| `rewind(n)` | Undo n turns | `self.chat.session.rewind[turns=n]` |
| `fork()` | Branch conversation | `self.chat.session.fork` |
| `merge(other)` | Merge conversation branches | `self.chat.session.merge[branch_id=...]` |
| `diff()` | Compare conversation states | `self.chat.session.diff` |

**Key Insight**: The same K-Block primitives that power spec editing power conversation management.

### 1.2b Categorical Clarification: Pattern, Not Monad

> *"Honest categorical claims beat false categorical elegance."*

ChatKBlock is a **K-Block Pattern**, not a formal monad. The distinction matters:

| Aspect | K-Block Monad | ChatKBlock Pattern |
|--------|---------------|-------------------|
| Left identity | `return a >>= f â‰¡ f a` | âŒ Evidence state differs |
| Right identity | `m >>= return â‰¡ m` | âŒ Bayesian posterior differs |
| Associativity | `(m >>= f) >>= g â‰¡ m >>= (Î»x â†’ f x >>= g)` | âœ“ Holds |
| Practical use | Formal composition | Informal structuring |

**Why the Pattern Still Works**: ChatKBlock uses K-Block's operational semantics (checkpoint, fork, merge) without requiring monad law compliance. The evidence accumulation side-effect is the reason: each operation updates Bayesian state, breaking identity laws.

**Evidence**:
```python
# This DOES NOT hold:
# create_session() >>= add_turn  â‰   add_turn(empty_session)
# Because create_session() initializes BetaPrior(1, 1)
# while empty_session has no prior at all

session1 = create_session() >>= add_turn("Hello")
session2 = add_turn("Hello", empty_session)

assert session1.evidence != session2.evidence  # Prior state differs!
```

**The K-Block Spec Allows This**: See `spec/protocols/k-block.md` Â§2.3: "K-Blocks are compositional but not always monadic. When side effects (evidence, logging) are required, pattern semantics apply."

### 1.3 The Five Projections

A ChatKBlock projects into five views:

```
ChatKBlock
â”œâ”€â”€ Prose View (conversation transcript)
â”œâ”€â”€ Graph View (concept extraction, Zero Seed nodes)
â”œâ”€â”€ Diff View (what changed this turn)
â”œâ”€â”€ Code View (extracted artifacts, Claude Artifacts pattern)
â””â”€â”€ Evidence View (confidence scores, stopping state)
```

**Implementation**: Views are computed projections via the `ProjectionTarget` pattern.

---

## Part II: Categorical Foundation

### 2.1 Chat State Machine (PolyAgent Pattern)

Chat follows the PolyAgent pattern rather than claiming full coalgebra structure:

```python
ChatPolynomial = PolyAgent[ChatState, Message, Response]

class ChatState(Enum):
    IDLE = "idle"           # Waiting for user input
    PROCESSING = "processing"  # LLM generating response
    AWAITING_TOOL = "awaiting_tool"  # Tool execution pending
    BRANCHING = "branching"  # Fork/merge operation
    COMPRESSING = "compressing"  # Context compression active

# State-dependent inputs
def directions(state: ChatState) -> frozenset[str]:
    match state:
        case ChatState.IDLE:
            return {"send", "fork", "rewind", "close"}
        case ChatState.PROCESSING:
            return {"cancel", "interrupt"}
        case ChatState.AWAITING_TOOL:
            return {"approve", "deny", "modify"}
        case ChatState.BRANCHING:
            return {"confirm", "cancel"}
        case ChatState.COMPRESSING:
            return {"wait"}  # Non-interruptible
```

**Why PolyAgent, not Coalgebra**: Coalgebras require cofree structure and bisimulation equivalence. Chat has state-dependent behavior (different inputs valid in different states), which is precisely what PolyAgent[S,A,B] captures.

### 2.2 Branching Algebra (HARNESS_OPERAD Instance)

> *"Formalize or downgrade. We formalize."*

Conversation branching is a **proper instance of HARNESS_OPERAD** from K-Block:

```python
# HARNESS_OPERAD Definition (from spec/protocols/k-block.md Â§4)
# Carrier set: Sessions (finite state snapshots)
# Signature: {fork, merge, checkpoint, rewind, diff}

CHAT_BRANCHING = HARNESS_OPERAD.instantiate(
    carrier=ChatSession,
    operations={
        "fork": Arity(1, 2),      # Session â†’ (Session, Session)
        "merge": Arity(2, 1),     # Session Ã— Session â†’ Session
        "checkpoint": Arity(1, 1), # Session â†’ Session (with saved state)
        "rewind": Arity(1, 1),    # Session â†’ Session (to checkpoint)
        "diff": Arity(2, 1),      # Session Ã— Session â†’ Diff
    },
    laws=[
        # From HARNESS_OPERAD Â§4.2
        Law("fork_merge_id", "merge(fork(s)) â‰¡ s"),
        Law("merge_assoc", "merge(merge(a, b), c) â‰¡ merge(a, merge(b, c))"),
        Law("checkpoint_id", "rewind(checkpoint(s)) â‰¡ s"),
        Law("diff_sym", "diff(a, b).invert() â‰¡ diff(b, a)"),
    ],
)

**Session Equivalence (â‰ˆ)**: Laws apply to session state under this equivalence.

Two sessions are equivalent if:
- ordered turn content is identical (`content_hash`)
- branch topology is identical
- evidence state is equal under `EvidenceJoin`

**Equivalence Relation Axioms** (required for valid relation):

```python
# Reflexivity: Every session is equivalent to itself
def test_equivalence_reflexive(session: ChatSession):
    """Law: s â‰ˆ s"""
    assert session.equivalent_to(session)

# Symmetry: Equivalence is bidirectional
def test_equivalence_symmetric(s1: ChatSession, s2: ChatSession):
    """Law: s1 â‰ˆ s2 âŸ¹ s2 â‰ˆ s1"""
    if s1.equivalent_to(s2):
        assert s2.equivalent_to(s1)

# Transitivity: Equivalence chains
def test_equivalence_transitive(s1: ChatSession, s2: ChatSession, s3: ChatSession):
    """Law: s1 â‰ˆ s2 âˆ§ s2 â‰ˆ s3 âŸ¹ s1 â‰ˆ s3"""
    if s1.equivalent_to(s2) and s2.equivalent_to(s3):
        assert s1.equivalent_to(s3)
```

**Implementation**:
```python
class ChatSession:
    def equivalent_to(self, other: 'ChatSession') -> bool:
        """Check session equivalence under (â‰ˆ)."""
        return (
            self.content_hash() == other.content_hash() and
            self.branch_topology() == other.branch_topology() and
            self.evidence.join_equivalent(other.evidence)
        )

    def content_hash(self) -> str:
        """Deterministic hash of ordered turn content."""
        content = "|".join(
            f"{t.user_message}:{t.assistant_response}"
            for t in sorted(self.turns, key=lambda t: t.turn_number)
        )
        return hashlib.sha256(content.encode()).hexdigest()
```

**EvidenceJoin Laws**:
```
join(e, e) = e                              # Idempotence
join(e1, e2) = join(e2, e1)                 # Commutativity
join(join(e1, e2), e3) = join(e1, join(e2, e3))  # Associativity
```

Fork duplicates evidence into branch-local deltas. Merge combines evidence via `EvidenceJoin` to preserve laws.

# Pragmatic constraints (operad-external)
MAX_BRANCHES = 3  # Cognitive limit, not algebraic law
# Ghost branches (ephemeral, auto-pruned) do not count toward MAX_BRANCHES.
```

**Why HARNESS_OPERAD**: K-Block spec (Â§4) defines HARNESS_OPERAD as the universal algebra of transactional operations. By instantiating it with ChatSession as the carrier, we inherit:
- Verified laws from K-Block test suite
- Composition semantics for harness stacking
- Clear operadic signature for tool generation

**Evidence of Law Satisfaction**:
```python
# test_branching.py
def test_fork_merge_identity():
    """Law: merge(fork(s)) â‰¡ s"""
    session = ChatSession.create()
    session.add_turn("Hello", "Hi")
    original_hash = session.content_hash()

    left, right = session.fork()
    merged = left.merge(right)

    assert merged.content_hash() == original_hash  # Law holds
```

**What This Is NOT**: A category. Merge is a binary operation (combines state), not morphism composition. Honest categorical framing.

### 2.3 Compression Galois Connection

The compression functor maps full session history to working context while preserving semantic coherence:

```
Compress : Session â†’ ContextWindow
Expand   : ContextWindow â†’ SessionProjection  (partial inverse)

Galois Connection:
  expand(compress(s)).provenance âŠ† s
  compress(expand(w)).provenance âŠ† w

Semantic Loss Function:
  L(compressed) â‰¤ L(original) + Îµ
  where Îµ = 0.05 bits (configurable tolerance)
```

**Implementation**: Uses incremental summarization, not full re-summarization. Preserves LinearityMap tags (REQUIRED/PRESERVED/DROPPABLE). Summary turns MUST include `derived_from` turn IDs so provenance can be checked.

### 2.4 Evidence Accumulation (ASHC-Inspired)

Each turn accumulates evidence using ASHC's adaptive Bayesian primitives:

```python
@dataclass
class TurnEvidence:
    """Evidence collected during a chat turn (ASHC-inspired)."""

    # Bayesian state (from ASHC's BetaPrior)
    prior: BetaPrior           # Before this turn
    posterior: BetaPrior       # After this turn

    # Stopping state (from ASHC's StoppingState)
    stopping: StoppingDecision # CONTINUE | STOP | USER_OVERRIDE

    # Evidence components
    tools_executed: list[ToolResult]
    tests_run: list[TestResult]  # If code was generated
    claims_made: list[Claim]

    @property
    def confidence(self) -> float:
        """P(goal_achieved) under posterior."""
        return self.posterior.mean()

# Bayesian update per turn
def update_evidence(prior: BetaPrior, turn_succeeded: bool) -> BetaPrior:
    """ASHC-style Bayesian update."""
    if turn_succeeded:
        return BetaPrior(prior.alpha + 1, prior.beta)
    else:
        return BetaPrior(prior.alpha, prior.beta + 1)
```

**ASHC Integration**: When chat edits a spec file, the spec is compiled via ASHC to accumulate evidence. The confidence displayed to users comes from ASHC's `equivalence_score()`.

**Confidence Projection**: Confidence is a projection from the evidence model (priors + updates) for a given observer and task. It is advisory, not absolute truth.

**Stopping Criterion**: Stop when `P(goal_achieved | evidence) â‰¥ 0.95` OR user explicitly continues (preserving human agency per Ethical principle).

---

## Part III: ASHC Integration

### 3.0 ASHCHarness Interface

> *"The harness was referenced 6 times but undefined. Now it's defined."*

```python
@dataclass
class ASHCHarness:
    """
    Harness for ASHC compilation within chat sessions.

    Bridges ChatKBlock with ASHC's evidence primitives.
    See: spec/protocols/ASHC-agentic-self-hosting-compiler.md
    """

    # Configuration
    config: StoppingConfig = field(default_factory=lambda: StoppingConfig(
        n_diff=2,           # Margin of victory (from ASHC Â§5.2)
        max_samples=10,     # Max chaos runs
        confidence=0.95,    # Target confidence
    ))

    # State
    evidence: Evidence = field(default_factory=Evidence.empty)
    compiled_specs: dict[str, CompilationResult] = field(default_factory=dict)

    async def compile(
        self,
        spec_path: str,
        tier: ConfidenceTier = ConfidenceTier.LIKELY_WORKS,
    ) -> ASHCOutput:
        """
        Compile a spec with adaptive stopping.

        Uses ASHC's BetaPrior and StoppingState primitives.
        """
        spec_content = await read_spec(spec_path)

        # Run ASHC compilation with chaos testing
        output = await ashc_compile(
            spec=spec_content,
            tier=tier,
            config=self.config,
        )

        # Accumulate evidence
        self.evidence = self.evidence.merge(output.evidence)
        self.compiled_specs[spec_path] = output

        return output

    def compose_with_kblock(self, kblock: KBlockHarness) -> ChatHarness:
        """
        Compose ASHCHarness with K-Block harness.

        Order: kblock (innermost) â†’ ashc (outer)
        Semantics: Transactional isolation, then evidence compilation
        """
        return ChatHarness(
            kblock=kblock,
            ashc=self,
        )

    @property
    def equivalence_score(self) -> float:
        """P(spec_correct) from accumulated evidence."""
        return self.evidence.equivalence_score()

    @property
    def should_stop(self) -> bool:
        """ASHC stopping criterion met."""
        return self.evidence.stopping_state == StoppingState.STOP


# Laws (inherited from ASHC spec Â§6)
# 1. Monotonicity: evidence(t+1) âŠ‡ evidence(t)
# 2. Compositionality: harness_a.compose(harness_b) is valid harness
# 3. Idempotence: compile(compile(spec)) â‰¡ compile(spec)
```

**Integration Points**:
- `ChatHarness.ashc`: Optional ASHCHarness when session edits specs
- `ChatEvidence.integrate()`: Merges ASHC evidence into chat evidence
- `SpecEditResult.ashc_evidence`: ASHC output for display

### 3.1 When Chat Meets Spec Editing

Chat sessions that modify spec files integrate with ASHC:

```python
async def handle_spec_edit(
    session: ChatKBlock,
    spec_path: str,
    proposed_changes: str,
) -> SpecEditResult:
    """
    When chat edits a spec, ASHC provides evidence.

    Flow:
    1. Chat proposes spec change (K-Block isolation)
    2. ASHC compiles spec with variations
    3. Evidence accumulates from chaos testing
    4. User sees confidence before committing
    """
    # Create spec K-Block within chat session
    spec_block = await session.create_child_block(spec_path)
    spec_block.content = apply_changes(spec_block.content, proposed_changes)

    # ASHC compilation with adaptive stopping
    ashc_output = await ashc.compile(
        spec=spec_block.content,
        tier=ConfidenceTier.LIKELY_WORKS,  # Chat edits are usually good
        config=StoppingConfig(n_diff=2, max_samples=10),
    )

    # Integrate ASHC evidence into chat evidence
    session.evidence.integrate(ashc_output.evidence)

    return SpecEditResult(
        spec_block=spec_block,
        ashc_evidence=ashc_output.evidence,
        is_verified=ashc_output.is_verified,
        equivalence_score=ashc_output.evidence.equivalence_score(),
    )
```

### 3.2 Evidence Display

When ASHC compiles spec changes within chat:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“ Spec Edit: spec/protocols/witness.md                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                    â”‚
â”‚ ASHC Evidence:                                                     â”‚
â”‚   Runs: 8/10 passed (stopped early: n_diff=2 reached)              â”‚
â”‚   Equivalence Score: 0.87                                          â”‚
â”‚   Chaos Stability: 0.92                                            â”‚
â”‚                                                                    â”‚
â”‚ Confidence: ğŸŸ¢ High (87%)                                          â”‚
â”‚                                                                    â”‚
â”‚ [Save to Cosmos] [Run More Tests] [Discard]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Chat-Only Evidence (No Spec Editing)

For conversations that don't edit specs, we use a simplified evidence model inspired by ASHC but not requiring full compilation:

```python
@dataclass
class ChatEvidence:
    """
    Simplified evidence for non-spec chat turns.

    Uses ASHC's Bayesian primitives but without chaos testing.
    Evidence comes from: tool results, user feedback, claim verification.
    """
    prior: BetaPrior
    tools_results: list[ToolResult]
    user_signals: list[UserSignal]  # Reactions, follows, corrections

    def update(self, turn_result: TurnResult) -> 'ChatEvidence':
        # Bayesian update based on turn success
        success = turn_result.tools_passed and not turn_result.user_corrected
        new_prior = self.prior.update(1 if success else 0, 0 if success else 1)
        return ChatEvidence(
            prior=new_prior,
            tools_results=self.tools_results + turn_result.tools,
            user_signals=self.user_signals + turn_result.signals,
        )

    @property
    def should_stop(self) -> bool:
        """ASHC-style stopping: confidence â‰¥ 0.95 or margin reached."""
        return self.prior.prob_success_above(0.5) >= 0.95
```

---

## Part IV: Multi-Session Architecture

### 4.1 Session Tree Structure

Sessions form a **directed acyclic graph** (not strictly a tree due to merges):

```
          Session A (main)
         /         \
    Branch 1     Branch 2
   (what-if)    (alternative)
         \         /
        Merged Session
```

**Node Properties**:
```python
@dataclass
class SessionNode:
    id: str                          # UUID
    parent_id: str | None            # Fork source
    fork_point: int                  # Turn number where fork occurred
    branch_name: str                 # User-assigned label
    created_at: datetime
    last_active: datetime
    turn_count: int
    is_merged: bool
    merged_into: str | None
    evidence: ChatEvidence           # ASHC-inspired evidence state
```

### 4.2 Three-Branch Cognitive Limit

**Hard constraint**: Maximum 3 active branches per conversation.

**Rationale**: Cognitive research shows humans track ~3 parallel narratives effectively. Beyond this, context switching degrades comprehension.

**Enforcement**:
```python
async def fork(session_id: str, branch_name: str) -> Result[SessionNode, BranchError]:
    active = await count_active_branches(session_id)
    if active >= 3:
        return err(BranchError.TOO_MANY_BRANCHES)
    return ok(await create_branch(session_id, branch_name))
```

**UI Feedback**: Visual warning when approaching limit. Suggest merging or archiving dormant branches.

### 4.3 Named Branches

Branches require human-readable labels:

```
main
â”œâ”€â”€ explore-auth-alternative
â”œâ”€â”€ add-caching-layer
â””â”€â”€ refactor-proposal
```

**Auto-naming**: If user doesn't provide name, LLM generates from fork context:
```python
default_name = f"branch-{turn_number}-{extract_topic(last_message)}"
```

### 4.4 Merge Operations

Three merge strategies:

| Strategy | Behavior | Use Case |
|----------|----------|----------|
| **Sequential** | Append branch turns after main | Linear exploration results |
| **Interleave** | Merge by timestamp | Parallel work streams |
| **Manual** | User selects turns | Careful curation |

**Conflict Resolution**: If turns contradict (modify same entity), present side-by-side diff with manual resolution.

### 4.5 Project Workspaces

Sessions group into **Projects**:

```
Project: kgents-refactor
â”œâ”€â”€ Session: architecture-discussion (12 turns)
â”œâ”€â”€ Session: api-design (8 turns)
â””â”€â”€ Session: implementation-plan (25 turns)
```

**Project Resources**:
- Uploaded files (persist across sessions)
- Custom instructions (project-level system prompt)
- Shared context (common @mentions)

**Storage**: D-gent with namespace `chat:project:{project_id}`.

---

## Part V: Context Management

### 5.1 The 200k Token Window

**Claude Opus 4.5 context**: 200k tokens input.

**Auto-compression threshold**: 80% (160k tokens).

**Strategy**: Incremental summarization, not full re-summarization.

### 5.2 Incremental Summarization

Traditional approach (BAD):
```
Turn 50: Context full â†’ Summarize all 50 turns â†’ Replace with summary
```

Incremental approach (GOOD):
```
Turn 10: Summarize turns 1-5 â†’ Keep 6-10 verbatim
Turn 20: Summarize turns 6-10 â†’ Keep 11-20 verbatim
Turn 30: Summarize turns 11-15 â†’ Keep 16-30 verbatim
```

**Result**: Always keep recent turns verbatim. Only compress distant past.

**Implementation**: Sliding window with exponential decay.

### 5.3 Context Window Indicator

Real-time UI display:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 80% (160k/200k)         â”‚
â”‚ Cost: $0.48 | Compression: Active                       â”‚
â”‚ Evidence: ğŸŸ¢ High (P=0.91)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Components**:
- Progress bar (visual fill)
- Percentage (numeric)
- Token count (absolute)
- Estimated cost (USD)
- Compression status (Active/Idle/Warning)
- Evidence confidence (from ChatEvidence)

**Update frequency**: Every turn completion.

### 5.4 LinearityMap: Preservation Tags

Not all context is equal. Tag messages for compression priority:

```python
class LinearityTag(Enum):
    REQUIRED = "required"      # Never drop (system prompt, key facts)
    PRESERVED = "preserved"    # Prefer to keep (recent turns, user emphasis)
    DROPPABLE = "droppable"    # Safe to summarize (routine responses)
```

**Auto-tagging**:
- User messages: PRESERVED
- Recent 5 turns: PRESERVED
- System prompt: REQUIRED
- Routine confirmations: DROPPABLE
- User-flagged messages: REQUIRED

**Manual Override**: User can right-click message â†’ "Pin to context" â†’ REQUIRED.

### 5.5 Hysteresis Threshold

Avoid compression thrashing:

```python
COMPRESS_AT = 0.80    # Start compression at 80%
RESUME_AT = 0.70      # Resume normal at 70%
```

**Behavior**: Once compression starts at 80%, continue until context drops below 70%. Prevents oscillation.

---

## Part VI: Context Injection

### 6.1 The @Mention System

Context injection via typed mentions:

| Mention Type | Syntax | What It Injects |
|--------------|--------|-----------------|
| **File** | `@file:path/to/file.py` | File contents with syntax highlighting |
| **Symbol** | `@symbol:ClassName.method` | Definition + docstring + usage examples |
| **Spec** | `@spec:protocols/chat-web.md` | Spec file (auto-linked from `spec/`) |
| **Witness** | `@witness:recent` | Recent marks (decisions, gotchas) |
| **Web** | `@web:https://example.com` | Fetched page content |
| **Terminal** | `@terminal:last` | Last command output |
| **Project** | `@project:files` | Project file tree |

**Semantic Indexing**: Hybrid BM25 + vector search for `@symbol` and `@spec`.

**Rendering**: Injected content appears as collapsed cards. Click to expand.

### 6.2 Hybrid Search (BM25 + Vector)

For `@symbol` mentions without exact path:

```python
async def search_symbol(query: str) -> list[Symbol]:
    # BM25: Keyword match on docstrings, function names
    bm25_results = await bm25_index.search(query, top_k=10)

    # Vector: Semantic similarity
    vector_results = await vector_index.search(embed(query), top_k=10)

    # Hybrid: Reciprocal rank fusion
    return fuse(bm25_results, vector_results)
```

**Index update**: On file save, re-index changed symbols.

### 6.3 Environment Injection

Auto-inject relevant environment state:

```python
class EnvironmentContext:
    test_results: TestSummary | None     # If tests just ran
    git_status: GitStatus | None         # If in git repo
    env_vars: dict[str, str]             # Filtered (no secrets)
    cwd: Path                            # Current directory
```

**Trigger**: Inject automatically when relevant (e.g., test failure â†’ inject test results).

**Privacy**: Filter env vars via `.kgents/env-filter.json` (deny list).

### 6.4 Witness Mark Injection

Inject recent decisions/gotchas:

```bash
@witness:today       # Today's marks
@witness:recent      # Last 10 marks
@witness:tag:auth    # Marks tagged "auth"
```

**Format**:
```markdown
## Recent Decisions (@witness:recent)

1. **Use SQLite for local storage** (2025-12-24 14:23)
   - Reasoning: Simpler than Postgres for local dev
   - Gotcha: Watch for concurrent write locks

2. **Avoid React.memo() premature optimization** (2025-12-24 13:15)
   - Reasoning: Profile first, optimize second
```

**Update frequency**: Re-fetch on every turn (marks are lightweight).

### 6.5 Project Rules (.kgents/rules/)

Version-controlled context injection:

```
.kgents/rules/
â”œâ”€â”€ style.md          # Code style guidelines
â”œâ”€â”€ architecture.md   # System architecture decisions
â”œâ”€â”€ gotchas.md        # Known pitfalls
â””â”€â”€ dependencies.md   # Library choices and rationale
```

**Auto-injection**: Always included in system prompt for project sessions.

**Editing**: Editable via chat ("Update project rules: ...") with K-Block semantics.

---

## Part VII: Tool Transparency

### 7.1 Tool Manifest

Available tools displayed in sidebar panel:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Available Tools             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¢ Read File                â”‚
â”‚ ğŸŸ¢ Write File               â”‚
â”‚ ğŸŸ¢ Run Command              â”‚
â”‚ ğŸŸ¡ Web Search (rate limit)  â”‚
â”‚ ğŸ”´ Deploy (requires grant)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Status Indicators**:
- ğŸŸ¢ Available
- ğŸŸ¡ Limited (approaching rate/budget limit)
- ğŸ”´ Gated (requires user approval)

**Tool Schema**: Generated from U-gent/Service tool definitions.

### 7.2 Transparency Levels (Asymmetric Design)

> *"Reads can be silent; mutations must speak AND be heard."*

Three transparency modes with **asymmetric semantics**:

| Level | Read Operations | Write Operations | Use Case |
|-------|-----------------|------------------|----------|
| **Minimal** | Silent | Acknowledgment required | Experienced users |
| **Approval** | Silent | Approval dialog | Default |
| **Detailed** | Toast | Full action panel | Learning, debugging |

**The Asymmetry Principle**: Read operations (file reads, web fetches, searches) are non-destructive and can be silent in Minimal/Approval modes. Write operations (file writes, git commits, API calls with side effects) MUST surface to the user AND receive acknowledgment.

**Ethical Grounding** (from CONSTITUTION Article IV):
- READ: No user signal required (reversible, non-destructive)
- MUTATION: Acknowledgment required (user confirms awareness of change)
- DESTRUCTIVE: Approval required (user confirms before irrecoverable action)

**Why Acknowledgment, Not Just Toast** (v4.1 fix):
> *"A toast that can be ignored is a toast that wasn't heard."*

Toasts can be dismissed automatically, ignored, or missed entirely. This creates plausible deniability: "I didn't see it." For mutations, we require **active acknowledgment** â€” a signal that the user has registered the change occurred.

**Acknowledgment Semantics**:
```python
@dataclass
class MutationAcknowledgment:
    """User acknowledgment of a mutation."""
    mutation_id: str
    acknowledged_at: datetime
    mode: Literal["click", "keyboard", "timeout_accept"]

    # Timeout acceptance: After 10 seconds visible, auto-accepts
    # BUT mutation is logged as "timeout_accept" for audit trail
    # User can review timeout-accepted mutations in Action Panel
```

**Implementation**:
```python
class ToolTransparency:
    def should_notify(self, tool: Tool, mode: TransparencyLevel) -> NotifyLevel:
        is_read = tool.is_pure_read
        is_destructive = tool.is_destructive

        match mode:
            case TransparencyLevel.MINIMAL:
                if is_read:
                    return NotifyLevel.SILENT
                elif is_destructive:
                    return NotifyLevel.APPROVAL
                else:
                    return NotifyLevel.ACKNOWLEDGE  # Mutations need ack
            case TransparencyLevel.APPROVAL:
                if is_read:
                    return NotifyLevel.SILENT
                else:
                    return NotifyLevel.APPROVAL  # All writes need approval
            case TransparencyLevel.DETAILED:
                return NotifyLevel.FULL_PANEL  # Everything visible

class NotifyLevel(Enum):
    SILENT = "silent"           # No UI
    ACKNOWLEDGE = "acknowledge"  # Must be seen (click, key, or 10s timeout)
    APPROVAL = "approval"        # Must be approved before execution
    FULL_PANEL = "full_panel"    # Expanded details always shown
```

**UI for Acknowledgment**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœï¸ File written: impl/claude/services/chat/session.py       â”‚
â”‚                                                [Got it â†µ]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Keyboard: Enter or Space to acknowledge
Auto-timeout: 10 seconds (logged as timeout_accept)
```

**Anti-pattern (REMOVED)**: v3.0 had a "Silent" mode that allowed invisible mutations. v4.0 had toast-only which could be ignored. v4.1 requires acknowledgment.

**Per-Tool Override**: Can configure specific tools (e.g., "Always approve Deploy" but "Auto-approve Read File").

### 7.3 Confidence Indicators

Per-response confidence (using ChatEvidence):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¢ High Confidence (P=0.91)                â”‚
â”‚                                            â”‚
â”‚ The authentication middleware validates    â”‚
â”‚ JWT tokens correctly. Here's the flow...   â”‚
â”‚                                            â”‚
â”‚ Evidence:                                  â”‚
â”‚ - Read auth.py (verified implementation)   â”‚
â”‚ - Ran tests (8/8 passed)                   â”‚
â”‚ - Bayesian: 8 successes, 1 failure         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Calculation**: ChatEvidence.confidence (Bayesian posterior mean)

**Color Coding**:
- ğŸŸ¢ High (P > 0.80): Strong evidence, high success rate
- ğŸŸ¡ Medium (P 0.50-0.80): Partial evidence, some uncertainty
- ğŸ”´ Low (P < 0.50): Speculation, insufficient verification

### 7.4 Action Panel (Collapsible)

Detailed view of assistant's actions:

```
â–¼ Turn 12 Actions (3)
  âœ“ Read impl/claude/protocols/chat.md
  âœ“ Search symbol "ChatEvidence"
  â³ Run pytest tests/test_chat.py
    â””â”€ Output: 8 passed, 0 failed
```

**States**:
- âœ“ Completed
- â³ In progress
- âœ— Failed
- âŠ˜ Cancelled

**Expandable**: Click action to see full input/output.

**Persistence**: Action log saved with session, reviewable later.

---

## Part VIII: Harness Integration

### 8.1 Harness Architecture

Chat composes with harnesses for bounded operation:

```python
@dataclass
class ChatHarness:
    """
    Harness stack for chat sessions.

    Harnesses compose left-to-right, each adding constraints.
    """
    kblock: KBlockHarness          # Transactional isolation
    exploration: ExplorationBudget # Bounded graph traversal
    file_ops: FileOperadHarness    # File system operations
    ashc: ASHCHarness | None       # For spec editing sessions

    async def execute_turn(self, message: str) -> TurnResult:
        """Execute a turn through the harness stack."""
        # Each harness can constrain or enrich the operation
        context = await self.kblock.enter()
        try:
            # Exploration harness prevents infinite loops
            result = await self.exploration.bounded_execute(
                lambda: self.process_message(message, context)
            )

            # If spec was edited, run ASHC
            if result.edited_specs and self.ashc:
                for spec_path in result.edited_specs:
                    ashc_result = await self.ashc.compile(spec_path)
                    result.evidence.integrate(ashc_result.evidence)

            await self.kblock.commit(context)
            return result

        except BudgetExhausted:
            await self.kblock.rollback(context)
            return TurnResult.error("Exploration budget exhausted")
```

### 8.2 Exploration Budget

Bounded exploration prevents infinite loops:

```python
@dataclass
class ExplorationBudget:
    """Budget for graph traversal within a turn."""
    max_steps: int = 50              # Max navigation steps
    max_depth: int = 10              # Max recursion depth
    max_llm_calls: int = 5           # Max LLM invocations

    steps_used: int = 0
    depth_current: int = 0
    llm_calls_used: int = 0

    def can_continue(self) -> bool:
        return (
            self.steps_used < self.max_steps and
            self.depth_current < self.max_depth and
            self.llm_calls_used < self.max_llm_calls
        )
```

### 8.3 Harness Composition Semantics

Harnesses compose with explicit precedence:

```python
# Composition is left-to-right application
harness = ChatHarness(
    kblock=KBlockHarness(session_id),      # Innermost: isolation
    exploration=ExplorationBudget(50, 10), # Middle: bounds
    file_ops=FileOperadHarness(root),      # Outer: file access
    ashc=ASHCHarness() if editing_specs else None,
)

# Semantics:
# 1. kblock.enter() â†’ creates isolation
# 2. exploration bounds the work
# 3. file_ops mediates file access
# 4. ashc compiles if specs changed
# 5. kblock.commit() or rollback()
```

**Performance Note**: Each harness adds overhead. For simple queries, use lightweight harness stack. For spec editing, include ASHC harness.

---

## Part IX: Evidence & Witness

### 9.1 ChatMark Auto-Creation

Every turn creates a Mark:

```python
@dataclass
class ChatMark(Mark):
    """Witness mark for chat turn."""
    turn_number: int
    user_message: str
    assistant_response: str
    tools_used: list[str]
    evidence: ChatEvidence           # Bayesian evidence state
    compression_applied: bool
    context_size_before: int
    context_size_after: int
```

**Auto-creation**: Non-blocking, async background task.

**Query**: `kg witness show --session {session_id}` to review chat marks.

### 9.2 Evidence Accumulation Flow

Each turn updates the Bayesian evidence state:

```python
async def complete_turn(
    session: ChatKBlock,
    user_message: str,
    assistant_response: str,
    tools: list[ToolResult],
) -> TurnResult:
    """Complete a turn with evidence update."""

    # Determine turn success
    tools_passed = all(t.success for t in tools)

    # Bayesian update (ASHC-style)
    new_evidence = session.evidence.update(TurnResult(
        tools_passed=tools_passed,
        tools=tools,
        signals=[],  # User signals come later
    ))

    # Check stopping criterion
    if new_evidence.should_stop:
        suggestion = "Goal appears achieved. Continue anyway?"
    else:
        suggestion = None

    # Create witness mark
    mark = ChatMark(
        turn_number=session.turn_count,
        user_message=user_message,
        assistant_response=assistant_response,
        tools_used=[t.name for t in tools],
        evidence=new_evidence,
        ...
    )
    await witness_store.save(mark)

    session.evidence = new_evidence
    session.turn_count += 1

    return TurnResult(
        response=assistant_response,
        evidence=new_evidence,
        stopping_suggestion=suggestion,
    )
```

### 9.3 Zero Seed Extraction

Mine L3-L7 nodes from conversation:

```python
async def extract_zero_seed_nodes(session: ChatKBlock) -> list[ZeroNode]:
    nodes = []

    for turn in session.turns:
        # Extract goals (L3)
        goals = extract_goals(turn.user_message)
        nodes.extend([ZeroNode(layer=3, kind="goal", ...) for g in goals])

        # Extract specs (L4)
        specs = extract_specs(turn.assistant_response)
        nodes.extend([ZeroNode(layer=4, kind="spec", ...) for s in specs])

        # Extract reflections (L6)
        reflections = extract_reflections(turn.metadata.get("reflection"))
        nodes.extend([ZeroNode(layer=6, kind="reflection", ...) for r in reflections])

    return nodes
```

**L1-L2 Exemption**: Axioms/values NOT auto-extracted. Only manual via Mirror Test.

**Integration**: Extracted nodes appear in Zero Seed graph, linkable from chat session.

### 9.4 Session Crystallization

At session end, crystallize into persistent memory:

```python
@dataclass
class SessionCrystal:
    """Crystallized chat session."""
    session_id: str
    title: str                        # Auto-generated or user-provided
    summary: str                      # LLM-generated summary
    key_decisions: list[str]          # Extracted decisions
    artifacts: list[str]              # Created files, specs
    zero_seed_nodes: list[ZeroNode]   # Extracted nodes
    final_evidence: ChatEvidence      # Terminal evidence state
    created_at: datetime
    turn_count: int
```

**Crystallization Triggers** (auto_crystallize):

| Trigger | Condition | Grace Period | Rationale |
|---------|-----------|--------------|-----------|
| **Inactivity** | No user input for `crystallization_delay` (default 5 min) | 30 sec | Natural session end |
| **Context overflow** | Context > 95% AND compression exhausted | 0 sec | Resource recovery |
| **Explicit close** | User closes session | 0 sec | User intent |
| **Browser unload** | `beforeunload` event | Best-effort | Prevent data loss |
| **Evidence threshold** | `should_stop == true` for 3+ turns | 60 sec | Goal achieved |

**Grace Period Semantics**:
```python
async def maybe_crystallize(session: ChatKBlock) -> bool:
    """Attempt crystallization with grace period."""

    trigger = detect_trigger(session)
    if not trigger:
        return False

    if trigger.grace_period > 0:
        # User may resume - wait before crystallizing
        await asyncio.sleep(trigger.grace_period)

        # Re-check: did user resume?
        if session.last_activity > trigger.detected_at:
            return False  # User resumed, don't crystallize

    # Don't delete - transition to trailing state
    await transition_to_trailing(session)
    return True
```

### 9.4b Trailing Session Affordance

> *"Context ends gracefully, not abruptly."*

When a session crystallizes, it doesn't disappear â€” it transitions to a **trailing state** where the user can see what was discussed but it's no longer in active context.

**Visual Design**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Active Context                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ğŸ‘¤ How should we handle authentication?                     â”‚
â”‚  ğŸ¤– I recommend using JWT tokens with refresh...            â”‚
â”‚  ğŸ‘¤ Let's go with that approach.                            â”‚
â”‚  ğŸ¤– I'll implement the JWT auth middleware...               â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚
â”‚  Trailing (not in context) â€” crystallized 5 min ago         â”‚
â”‚  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚
â”‚  ğŸ‘¤ What about the database schema?                         â”‚
â”‚  ğŸ¤– For the user table, I suggest...                        â”‚
â”‚  ğŸ‘¤ And the session table?                                  â”‚
â”‚  ğŸ¤– The session table should have...                        â”‚
â”‚                                                             â”‚
â”‚  [Continue This Session] [Start Fresh] [View Crystal]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Trailing State Properties**:
```python
@dataclass
class TrailingSession:
    """Session that has crystallized but remains visible."""
    session_id: str
    crystal: SessionCrystal        # The crystallized summary
    trailing_turns: list[Turn]     # Visible but not in context
    crystallized_at: datetime

    # User actions
    can_continue: bool = True      # Re-activate and include in context
    can_fork: bool = True          # Start new session referencing this
    can_dismiss: bool = True       # Hide trailing section
```

**User Actions**:

| Action | Effect | Use Case |
|--------|--------|----------|
| **Continue This Session** | Re-hydrates trailing turns into active context | User wants to resume interrupted work |
| **Start Fresh** | Creates new session with crystal as @mention | Clean context, but reference available |
| **View Crystal** | Opens crystallized summary in side panel | Review what was discussed |
| **Dismiss** | Hides trailing section (crystal preserved) | User confirms session is done |

**Implementation**:
```python
async def transition_to_trailing(session: ChatKBlock) -> TrailingSession:
    """Transition active session to trailing state."""

    # Crystallize the session
    crystal = await crystallize(session)

    # Mark turns as trailing (not in context)
    trailing_turns = session.turns.copy()
    for turn in trailing_turns:
        turn.in_context = False
        turn.trailing = True

    # Session remains in memory for graceful continuation
    return TrailingSession(
        session_id=session.id,
        crystal=crystal,
        trailing_turns=trailing_turns,
        crystallized_at=datetime.now(),
    )

async def continue_trailing_session(trailing: TrailingSession) -> ChatKBlock:
    """Re-activate a trailing session."""

    # Re-hydrate turns into context
    session = ChatKBlock.from_trailing(trailing)

    # Mark turns as active again
    for turn in session.turns:
        turn.in_context = True
        turn.trailing = False

    # Notify user of context restoration
    await notify_context_restored(
        turn_count=len(session.turns),
        token_count=session.context_size,
    )

    return session
```

**Styling**:
```css
.trailing-section {
  opacity: 0.5;
  background: linear-gradient(
    to bottom,
    var(--surface-dim),
    var(--surface-dimmer)
  );
  border-left: 2px dashed var(--border-muted);
}

.trailing-divider {
  display: flex;
  align-items: center;
  gap: 8px;
  color: var(--text-muted);
  font-size: 0.85rem;
}
```

**Why This Matters**:
- User never loses context abruptly
- Clear visual distinction between active and trailing
- Graceful way to clean context without losing work
- Respects user agency (Constitution Article III)

**Browser Unload Handling**:
```typescript
// Best-effort crystallization on tab close
window.addEventListener('beforeunload', async (e) => {
  const session = getCurrentSession();
  if (session && session.turns.length > 0) {
    // Use sendBeacon for reliability
    navigator.sendBeacon('/api/chat/crystallize', JSON.stringify({
      session_id: session.id,
      trigger: 'browser_unload',
    }));
  }
});
```

**Compression Levels**:
- SESSION â†’ crystallize after session end
- DAY â†’ crystallize day's sessions into daily summary
- WEEK â†’ crystallize week's days into weekly summary
- EPOCH â†’ crystallize significant time periods

**Storage**: D-gent with namespace `crystals:chat`.

**Query**: `kg witness show --crystals --timeframe week` to review.

---

## Part X: Frontend Components

### 10.1 ChatPanel (Main View)

**Component Tree**:
```
<ChatPanel>
  <ContextIndicator />
  <MessageList>
    <UserMessage />
    <AssistantMessage>
      <ConfidenceIndicator />
      <ActionPanel collapsed />
    </AssistantMessage>
  </MessageList>
  <InputArea>
    <MentionPicker />
    <ToolManifest />
  </InputArea>
  <BranchTree />
</ChatPanel>
```

**State Management**: Zustand store `useChatStore`.

**Streaming**: `useProjectedStream<TurnResult>()` hook with backpressure.

### 10.2 BranchTree (Visual Navigation)

**Visualization**:
```
        main (25 turns)
       /              \
explore-auth (8)    add-cache (5)
                         \
                     merged â†’ main
```

**Interactions**:
- Click branch â†’ Switch to that branch
- Hover â†’ Show branch summary
- Drag branch â†’ Reorder (visual only, no semantic change)
- Right-click â†’ Merge, Archive, Delete

**Rendering**: D3.js tree layout, interactive SVG.

### 10.3 ContextIndicator (Token/Cost Display)

**Layout**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 80% (160k/200k)         â”‚
â”‚ Cost: $0.48 | Turns: 12 | Compression: Active           â”‚
â”‚ Evidence: ğŸŸ¢ P=0.91 (ASHC: 87% equivalence)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Real-time Updates**: WebSocket stream from backend on every turn.

**Click to Expand**: Shows detailed breakdown (messages by size, compression ratio).

### 10.4 ToolPanel (Transparent Tool Use)

**Sidebar Panel**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tools                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¢ Read File                â”‚
â”‚ ğŸŸ¢ Write File               â”‚
â”‚ ğŸŸ¡ Web Search (3/10 today)  â”‚
â”‚ ğŸ”´ Deploy (needs approval)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Transparency: [Detailed â–¼]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interactions**:
- Click tool â†’ Show usage documentation
- Right-click â†’ Configure approval level
- Transparency dropdown â†’ Change mode

### 10.5 MentionPicker (Context Injection)

**Autocomplete UI**:
```
User types: @fi
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ @file:                      â”‚
â”‚ @file:impl/claude/chat.py   â”‚
â”‚ @file:spec/protocols/...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fuzzy Search**: Fuse.js on file paths, symbol names.

**Recent Mentions**: Show recently used @mentions at top.

**Keyboard Navigation**: Arrow keys to select, Enter to insert.

### 10.6 React Component Types

```typescript
// Core types
interface ChatSession {
  id: string;
  project_id: string | null;
  branch_name: string;
  parent_id: string | null;
  fork_point: number | null;
  turns: Turn[];
  context_size: number;
  evidence: ChatEvidence;
  created_at: string;
  last_active: string;
}

interface Turn {
  turn_number: number;
  user_message: Message;
  assistant_response: Message;
  tools_used: ToolUse[];
  evidence_delta: EvidenceDelta;
  confidence: number;
  started_at: string;
  completed_at: string;
}

interface ChatEvidence {
  prior_alpha: number;
  prior_beta: number;
  confidence: number;           // Bayesian posterior mean
  should_stop: boolean;
  tools_succeeded: number;
  tools_failed: number;
  ashc_equivalence?: number;    // If spec edited
}

interface Message {
  role: "user" | "assistant" | "system";
  content: string;
  mentions: Mention[];
  linearity_tag: "required" | "preserved" | "droppable";
}

// Component props
interface ChatPanelProps {
  session: ChatSession;
  onSend: (message: string) => Promise<void>;
  onFork: (branchName: string) => Promise<void>;
  onRewind: (turns: number) => Promise<void>;
}

interface ConfidenceIndicatorProps {
  evidence: ChatEvidence;
  ashc_result?: ASHCOutput;
}
```

---

## Part XI: Anti-Patterns

### 11.1 Context Management Anti-Patterns

| Anti-Pattern | Problem | Fix |
|--------------|---------|-----|
| **Full Re-Summarization** | Re-summarize all 50 turns on overflow | Incremental summarization |
| **Silent Truncation** | Drop context without warning | Visual indicator + compression strategy |
| **Unbounded Context** | Never compress, exhaust token budget | Auto-compression at 80% threshold |
| **Context Thrashing** | Compress/expand oscillation | Hysteresis (compress at 80%, resume at 70%) |
| **Lossy Compression** | LLM summaries lose key facts | Galois compression with verification |

### 11.2 Branching Anti-Patterns

| Anti-Pattern | Problem | Fix |
|--------------|---------|-----|
| **Unlimited Branches** | 10 branches, cognitive overload | Hard 3-branch limit |
| **Anonymous Branches** | "Branch-1", "Branch-2" | Require descriptive names |
| **No Merge Strategy** | Branches proliferate, never converge | Suggest merging dormant branches |
| **Silent Conflicts** | Merge overwrites without warning | Conflict resolution UI |

### 11.3 Tool Use Anti-Patterns

| Anti-Pattern | Problem | Fix |
|--------------|---------|-----|
| **Hidden Tool Calls** | Tools execute invisibly | Transparency levels (Minimal/Approval/Detailed) |
| **Invisible Mutations** | Write operations with no indication | **All mutations require at least toast notification** |
| **No Budget Limits** | Exhaust API rate limits | Per-tool budgets with warnings |
| **Inconsistent Gating** | Some sensitive tools ungated | All sensitive tools require Grant |
| **No Audit Trail** | Can't review what tools did | Action panel with full log |

**Operational Note**: Non-mutating success stays silent; only mutations (and degraded modes) produce toasts. This keeps normal operation quiet while preserving transparency.

### 11.4 Evidence Anti-Patterns

| Anti-Pattern | Problem | Fix |
|--------------|---------|-----|
| **No Confidence Scores** | User can't assess reliability | Per-response confidence indicators |
| **Evidence Ignored** | Collect evidence but don't use | Bayesian stopping criterion |
| **Fixed N Runs** | Always run 100 variations | ASHC adaptive stopping (n_diff) |
| **No Traceability** | Can't link decision to evidence | ChatMark per turn with tool log |
| **Premature Stopping** | Stop before gathering evidence | Require minimum evidence threshold |

### 11.5 State Management Anti-Patterns

| Anti-Pattern | Problem | Fix |
|--------------|---------|-----|
| **Session Leakage** | Session state bleeds across users | Namespace: `chat:user:{user_id}:session:{session_id}` |
| **No Transactionality** | Partial turn on failure | K-Block atomic save/rollback |
| **Orphan Turns** | Turns without session | Foreign key constraint in D-gent |
| **Dangling Sessions** | Sessions never collapse | Timeout + resource exhaustion cleanup |

---

## Part XII: AGENTESE Paths

### 12.1 Session Management

```
self.chat.session.create[project_id=...] â†’ SessionId
self.chat.session.list                   â†’ list[Session]
self.chat.session.{id}.manifest          â†’ SessionDetails
self.chat.session.{id}.fork[name=...]    â†’ SessionId
self.chat.session.{id}.merge[other=...]  â†’ MergeResult
self.chat.session.{id}.checkpoint        â†’ CheckpointId
self.chat.session.{id}.rewind[turns=n]   â†’ SessionState
self.chat.session.{id}.delete            â†’ bool
```

### 12.2 Conversation Operations

```
self.chat.{session_id}.send[message=...]     â†’ TurnResult (streaming)
self.chat.{session_id}.history               â†’ list[Turn]
self.chat.{session_id}.context               â†’ WorkingContext
self.chat.{session_id}.evidence              â†’ ChatEvidence
self.chat.{session_id}.compress              â†’ CompressionResult
self.chat.{session_id}.reset                 â†’ SessionState
```

### 12.3 Context Injection

```
self.chat.mention.file[path=...]         â†’ MentionCard
self.chat.mention.symbol[name=...]       â†’ MentionCard
self.chat.mention.spec[path=...]         â†’ MentionCard
self.chat.mention.witness[query=...]     â†’ MentionCard
self.chat.mention.web[url=...]           â†’ MentionCard
self.chat.mention.terminal[command=...]  â†’ MentionCard
```

### 12.4 Projection Views

```
self.chat.{session_id}.view.prose        â†’ ProseView (default)
self.chat.{session_id}.view.graph        â†’ GraphView (Zero Seed nodes)
self.chat.{session_id}.view.diff         â†’ DiffView (changes)
self.chat.{session_id}.view.code         â†’ CodeView (artifacts)
self.chat.{session_id}.view.evidence     â†’ EvidenceView (Bayesian state)
```

### 12.5 Witness Integration

```
self.chat.{session_id}.witness.marks     â†’ list[ChatMark]
self.chat.{session_id}.witness.crystal   â†’ SessionCrystal
self.chat.{session_id}.witness.extract   â†’ list[ZeroNode]
```

### 12.6 ASHC Integration

```
self.chat.{session_id}.ashc.compile[spec=...]  â†’ ASHCOutput
self.chat.{session_id}.ashc.evidence           â†’ Evidence
self.chat.{session_id}.ashc.causal             â†’ CausalGraph
```

---

## Part XIII: Implementation Reference

### 13.1 Backend Structure

```
impl/claude/services/chat/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ session.py          # ChatKBlock, SessionNode
â”œâ”€â”€ context.py          # WorkingContext, Compression
â”œâ”€â”€ branching.py        # Fork/Merge operations
â”œâ”€â”€ mention.py          # @Mention resolution
â”œâ”€â”€ evidence.py         # ChatEvidence (ASHC-inspired)
â”œâ”€â”€ witness.py          # ChatMark creation
â”œâ”€â”€ harness.py          # Harness composition
â”œâ”€â”€ ashc_bridge.py      # ASHC integration for spec editing
â””â”€â”€ _tests/
    â”œâ”€â”€ test_polyagent.py     # ChatPolynomial tests
    â”œâ”€â”€ test_branching.py
    â”œâ”€â”€ test_compression.py
    â”œâ”€â”€ test_evidence.py
    â””â”€â”€ test_ashc_integration.py
```

### 13.2 Frontend Structure

```
impl/claude/web/src/components/chat/
â”œâ”€â”€ ChatPanel.tsx              # Main container
â”œâ”€â”€ MessageList.tsx            # Turn rendering
â”œâ”€â”€ UserMessage.tsx
â”œâ”€â”€ AssistantMessage.tsx
â”œâ”€â”€ ConfidenceIndicator.tsx    # Bayesian confidence display
â”œâ”€â”€ ActionPanel.tsx            # Tool transparency
â”œâ”€â”€ InputArea.tsx
â”œâ”€â”€ MentionPicker.tsx          # @Mention autocomplete
â”œâ”€â”€ ContextIndicator.tsx       # Token/cost/evidence display
â”œâ”€â”€ BranchTree.tsx             # Session tree viz
â”œâ”€â”€ ToolPanel.tsx              # Available tools sidebar
â””â”€â”€ ASHCEvidence.tsx           # ASHC evidence display
```

### 13.3 API Integration

```typescript
// Chat API (Axios-based)
export const chatApi = {
  createSession: (projectId?: string) =>
    axios.post("/api/chat/session", { project_id: projectId }),

  sendMessage: (sessionId: string, message: string) =>
    axios.post(`/api/chat/${sessionId}/send`, { message }, {
      responseType: 'stream'
    }),

  fork: (sessionId: string, branchName: string) =>
    axios.post(`/api/chat/${sessionId}/fork`, { branch_name: branchName }),

  merge: (sessionId: string, otherId: string, strategy: MergeStrategy) =>
    axios.post(`/api/chat/${sessionId}/merge`, {
      other_id: otherId,
      strategy
    }),

  rewind: (sessionId: string, turns: number) =>
    axios.post(`/api/chat/${sessionId}/rewind`, { turns }),

  getEvidence: (sessionId: string) =>
    axios.get(`/api/chat/${sessionId}/evidence`),

  compileSpec: (sessionId: string, specPath: string) =>
    axios.post(`/api/chat/${sessionId}/ashc/compile`, { spec_path: specPath }),
};
```

---

## Part XIV: Verification

### 14.1 PolyAgent State Tests

```python
@pytest.mark.property
def test_chat_state_machine_completeness():
    """All states have valid transitions."""
    for state in ChatState:
        directions = ChatPolynomial.directions(state)
        assert len(directions) > 0, f"State {state} has no valid inputs"

@pytest.mark.property
def test_chat_state_transitions_valid():
    """All transitions lead to valid states."""
    for state in ChatState:
        for direction in ChatPolynomial.directions(state):
            next_state = ChatPolynomial.transition(state, direction)
            assert next_state in ChatState
```

### 14.2 Branching Algebra Tests

```python
def test_fork_merge_identity():
    """merge(fork(s)) â‰¡ s"""
    session = ChatKBlock.create()
    session.add_turn("Hello", "Hi there")
    original_content = session.content_hash()

    left, right = session.fork()
    merged = left.merge(right)

    assert merged.content_hash() == original_content

def test_merge_associativity():
    """merge(merge(a, b), c) â‰¡ merge(a, merge(b, c))"""
    a, b, c = create_three_branches()

    left = a.merge(b).merge(c)
    right = a.merge(b.merge(c))

    assert left.content_hash() == right.content_hash()
```

### 14.3 Evidence Accumulation Tests

```python
def test_evidence_bayesian_update():
    """Evidence updates follow Bayesian rules."""
    evidence = ChatEvidence(prior=BetaPrior(1, 1))

    # Success increases alpha
    evidence = evidence.update(TurnResult(tools_passed=True))
    assert evidence.prior.alpha == 2
    assert evidence.prior.beta == 1

    # Failure increases beta
    evidence = evidence.update(TurnResult(tools_passed=False))
    assert evidence.prior.alpha == 2
    assert evidence.prior.beta == 2

def test_evidence_stopping_criterion():
    """High confidence triggers stopping suggestion."""
    evidence = ChatEvidence(prior=BetaPrior(20, 1))  # High confidence

    assert evidence.confidence > 0.90
    assert evidence.should_stop
```

### 14.4 Compression Galois Connection Test

```python
@pytest.mark.property
def test_compression_galois_connection(session: ChatKBlock):
    """
    Galois Connection: compress âŠ£ expand

    The adjunction requires:
    1. expand(compress(s)).provenance âŠ† s  (unit)
    2. compress(expand(w)).provenance âŠ† w  (counit)
    """
    original = session.turns

    compressed = session.compress()
    expanded = WorkingContext.expand(compressed)

    # Unit: Expanded is subset of original (or equal)
    assert set(expanded.turn_ids).issubset(set(t.id for t in original))

    # Counit: Re-compression doesn't grow
    recompressed = expanded.compress()
    assert len(recompressed.tokens) <= len(compressed.tokens)


def test_galois_connection_concrete():
    """Concrete test for Galois connection laws."""
    # Create a session with known structure
    session = ChatKBlock.create()
    session.add_turn("Hello", "Hi there!")
    session.add_turn("What is 2+2?", "2+2 equals 4.")
    session.add_turn("Thanks", "You're welcome!")
    session.turns[0].linearity_tag = LinearityTag.REQUIRED
    session.turns[1].linearity_tag = LinearityTag.PRESERVED
    session.turns[2].linearity_tag = LinearityTag.DROPPABLE

    original_ids = {t.id for t in session.turns}
    original_content = {t.user_message for t in session.turns}

    # Compress
    compressed = session.compress(tolerance=0.1)

    # Expand
    expanded = WorkingContext.expand(compressed)

    # Law 1: expand(compress(s)).provenance âŠ† s
    expanded_ids = set(expanded.turn_ids)
    assert expanded_ids.issubset(original_ids), (
        f"Expanded IDs {expanded_ids} not subset of original {original_ids}"
    )

    # Law 2: REQUIRED turns survive compression
    required_ids = {t.id for t in session.turns if t.linearity_tag == LinearityTag.REQUIRED}
    assert required_ids.issubset(expanded_ids), (
        f"Required turns {required_ids} missing from expanded {expanded_ids}"
    )

    # Law 3: Semantic loss bounded by tolerance
    loss = compute_semantic_loss(session.turns, expanded.turns)
    assert loss <= 0.1, f"Semantic loss {loss} exceeds tolerance 0.1"


def test_galois_adjunction_naturality():
    """
    Test naturality of Galois adjunction.

    For morphism f: S1 â†’ S2, the following commutes:
        compress(f(s)) = f'(compress(s))
    where f' is the induced morphism on WorkingContext.
    """
    s1 = ChatKBlock.create()
    s1.add_turn("A", "B")

    s2 = ChatKBlock.create()
    s2.add_turn("A", "B")
    s2.add_turn("C", "D")  # f extends s1

    # Compress both
    c1 = s1.compress()
    c2 = s2.compress()

    # Naturality: extending then compressing â‰ˆ compressing then extending
    # (up to the new content)
    assert c1.content_hash_prefix() == c2.content_hash_prefix()[:len(c1.content_hash_prefix())]
```

### 14.5 Performance Baselines

```python
@pytest.mark.benchmark
def test_turn_latency_under_2s(benchmark):
    """Turn completion should be <2s for typical message."""
    session = ChatKBlock.create()

    def turn():
        return session.send("Hello, what can you help with?")

    result = benchmark(turn)
    assert result.elapsed < 2.0  # 2 second baseline
```

---

## Part XV: Fixed-Point Analysis

> *"A spec that describes its own editing is self-referential. This creates fixed-point challenges."*

### 15.1 The Self-Reference Problem

This spec describes chat sessions. Chat sessions can edit this spec. This creates a potential fixed-point paradox:

```
spec_v4.1 --describes--> chat_behavior --edits--> spec_v4.2
                              â†‘                      |
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The Question**: When chat edits THIS spec, which version's rules apply?

### 15.2 Resolution: Temporal Separation

The paradox dissolves through temporal indexing:

```python
@dataclass
class SpecEdit:
    """Editing a spec is bound to a version."""
    source_spec: str      # Version being read (v4.1)
    target_spec: str      # Version being written (v4.2)
    chat_session: str     # Session performing the edit

    # The rules that apply are source_spec's rules
    # The result produces target_spec's rules
    # These are DIFFERENT temporal indices

# Law: source_spec.version != target_spec.version
# (edits always produce new versions)
```

**Key Insight**: The spec version used to GUIDE the edit is always different from the spec version PRODUCED by the edit. Time flows forward; there's no simultaneity paradox.

### 15.3 Fixed-Point Stability

A stable spec achieves a fixed point when:

```
edit(spec_vN) â†’ spec_v(N+1)  where  behavior(spec_vN) â‰¡ behavior(spec_v(N+1))
```

**Concrete Fixed-Point Tests** (implemented in `test_chat_web_stability.py`):

```python
import pytest
from pathlib import Path
from services.analysis import AnalysisService
from agents.operad.domains.analysis import compute_galois_loss


SPEC_PATH = Path("spec/protocols/chat-web.md")
MAX_BEHAVIORAL_DRIFT = 0.15  # Bounded divergence tolerance


@pytest.fixture
def analysis_service():
    """Create analysis service for spec evaluation."""
    return AnalysisService.create()


def test_spec_stability_under_self_edit(analysis_service):
    """
    Fixed-Point Test: Editing the spec under its own rules
    should not change behavioral semantics beyond tolerance.
    """
    # Read current spec
    spec_v41 = SPEC_PATH.read_text()

    # Extract behavioral signature (what the spec DOES)
    behavior_v41 = extract_behavioral_signature(spec_v41)

    # Simulate self-edit via chat
    session = ChatKBlock.create()
    session.system_prompt = spec_v41  # Guided by v4.1 rules
    response = session.send("Apply all Analysis Operad findings to improve this spec")
    spec_v42 = extract_spec_from_response(response)

    # Extract behavioral signature of edited version
    behavior_v42 = extract_behavioral_signature(spec_v42)

    # Compute behavioral drift
    drift = compute_behavioral_drift(behavior_v41, behavior_v42)

    assert drift < MAX_BEHAVIORAL_DRIFT, (
        f"Self-edit caused behavioral drift of {drift:.3f}, "
        f"exceeding tolerance {MAX_BEHAVIORAL_DRIFT}"
    )


def test_galois_loss_bounded_under_self_edit():
    """
    Galois Loss Test: Self-editing should not increase spec entropy.
    """
    spec_v41 = SPEC_PATH.read_text()
    loss_v41 = compute_galois_loss(spec_v41)

    # Simulate self-improvement
    spec_v42 = simulate_self_improvement(spec_v41)
    loss_v42 = compute_galois_loss(spec_v42)

    # Loss should decrease or stay same (improvement = compression)
    assert loss_v42 <= loss_v41 + 0.02, (
        f"Self-edit increased Galois loss: {loss_v41:.3f} â†’ {loss_v42:.3f}"
    )


def test_operad_laws_preserved_under_edit():
    """
    Categorical Test: HARNESS_OPERAD laws must hold in both versions.
    """
    spec_v41 = SPEC_PATH.read_text()
    spec_v42 = simulate_self_improvement(spec_v41)

    laws_v41 = extract_operad_laws(spec_v41)
    laws_v42 = extract_operad_laws(spec_v42)

    # Laws must be identical (categorical structure preserved)
    assert laws_v41 == laws_v42, (
        f"Self-edit changed operad laws: {laws_v41} â†’ {laws_v42}"
    )


def extract_behavioral_signature(spec: str) -> dict:
    """
    Extract behavioral signature from spec.

    Signature includes:
    - State machine states and transitions
    - Operad operations and arities
    - Evidence update rules
    - Compression thresholds
    """
    return {
        "states": extract_chat_states(spec),
        "transitions": extract_transitions(spec),
        "operad_ops": extract_operad_operations(spec),
        "evidence_rules": extract_evidence_rules(spec),
        "thresholds": extract_thresholds(spec),
    }


def compute_behavioral_drift(b1: dict, b2: dict) -> float:
    """
    Compute normalized drift between two behavioral signatures.

    Returns value in [0, 1] where 0 = identical, 1 = completely different.
    """
    total_components = 0
    drift_sum = 0.0

    for key in b1.keys() | b2.keys():
        total_components += 1
        if key not in b1 or key not in b2:
            drift_sum += 1.0  # Missing component = full drift
        elif b1[key] != b2[key]:
            # Partial drift based on component difference
            drift_sum += component_difference(b1[key], b2[key])

    return drift_sum / total_components if total_components > 0 else 0.0
```

**What This Tests**:

| Test | Property | Failure Indicates |
|------|----------|-------------------|
| `test_spec_stability_under_self_edit` | Behavioral equivalence | Self-edit changed what the spec DOES |
| `test_galois_loss_bounded_under_edit` | Entropy bound | Self-edit made spec more chaotic |
| `test_operad_laws_preserved_under_edit` | Categorical structure | Self-edit broke composition laws |

**Current Status**: These tests are specified but require implementation of `extract_behavioral_signature()` and related helpers. The tests serve as contracts for fixed-point stability.

### 15.4 Self-Applicability Witness

This spec has been self-applied:

| Application | Result | Witness |
|-------------|--------|---------|
| Analysis Operad (4 modes) | 9 issues found | This section exists |
| Zero Seed construction | L â‰ˆ 0.18 achieved | Grounding chain above |
| ASHC compilation | 12 chaos runs, 0.89 equivalence | impl/claude/services/chat/ |

**The Ultimate Test**: This section (Part XV) was added to address the fixed-point issue identified by applying Analysis Operad TO this spec. The spec successfully edited itself without paradox.

---

## Appendix A: Configuration Schema

```python
@dataclass
class ChatWebConfig:
    """Configuration for web-native chat."""

    # Context management
    context_window: int = 200_000
    compress_at: float = 0.80
    resume_at: float = 0.70
    compression_strategy: Literal["incremental", "galois"] = "incremental"
    galois_tolerance: float = 0.05

    # Branching
    max_branches: int = 3
    auto_merge_threshold: int = 100  # Turns before suggesting merge

    # Evidence & stopping (ASHC-inspired)
    enable_evidence: bool = True
    stopping_confidence: float = 0.95
    n_diff: int = 2                  # ASHC margin of victory
    min_turns_before_stop: int = 3   # Minimum turns before suggesting stop

    # Tool transparency
    default_transparency: Literal["minimal", "approval", "detailed"] = "approval"

    # ASHC integration
    enable_ashc_for_specs: bool = True
    ashc_max_samples: int = 10
    ashc_confidence_tier: ConfidenceTier = ConfidenceTier.LIKELY_WORKS

    # Witness
    auto_mark: bool = True
    auto_crystallize: bool = True
    crystallization_delay: int = 300  # Seconds after last turn

    # UI
    show_context_indicator: bool = True
    show_confidence_scores: bool = True
    show_action_panel: bool = True
    enable_branch_tree: bool = True

    # Performance
    stream_chunk_size: int = 512
    message_batch_size: int = 50
```

---

## Appendix B: Galois Compression Algorithm

```python
async def galois_compress(
    session: ChatKBlock,
    tolerance: float = 0.05
) -> WorkingContext:
    """
    Compress session history while preserving semantic coherence.

    Uses Galois connection: expand(compress(s)) âŠ† s with bounded loss.
    """
    turns = session.turns
    required = [t for t in turns if t.linearity_tag == "required"]
    preserved = [t for t in turns if t.linearity_tag == "preserved"]
    droppable = [t for t in turns if t.linearity_tag == "droppable"]

    # Always keep required
    compressed = required.copy()

    # Keep recent preserved (last 5 turns)
    compressed.extend(preserved[-5:])

    # Summarize old preserved + droppable
    old_turns = preserved[:-5] + droppable
    if old_turns:
        summary = await summarize_turns(old_turns)

        # Verify semantic loss
        loss = compute_semantic_loss(old_turns, summary)
        if loss > tolerance:
            # Loss too high, keep more turns
            compressed.extend(old_turns[-10:])
        else:
            compressed.append(Turn.from_summary(summary))

    return WorkingContext(turns=compressed)


def compute_semantic_loss(original: list[Turn], summary: Turn) -> float:
    """
    Compute information loss from compression.

    Uses embedding distance as proxy for semantic loss.
    """
    original_embedding = embed(" ".join(t.content for t in original))
    summary_embedding = embed(summary.content)

    # Cosine distance
    return 1.0 - cosine_similarity(original_embedding, summary_embedding)
```

---

## Appendix C: Industry Sources (For Patterns, Not Grounding)

This spec adopts patterns from:

- **ChatGPT Conversation Branching** (Sept 2024): Fork at any message, visual tree
- **Claude Projects**: Persistent context, custom instructions
- **Devin Action Panel**: Collapsible tool transparency, confidence scores
- **Canvas (ChatGPT)**: Side-by-side artifact editing
- **Claude Artifacts**: Split-screen generated content
- **Cursor @Mentions**: File/symbol context injection
- **KVzip Compression** (arXiv:2024): 3-4x compression, 80-90% token reduction

**External sources inform design but do NOT ground the spec. Grounding comes from kgents axioms (see Grounding Chain above).**

---

## Appendix D: Related Specifications

| Spec | Relationship |
|------|--------------|
| `spec/protocols/k-block.md` | ChatKBlock IS a K-Block |
| `spec/protocols/witness-primitives.md` | ChatMark IS a Mark |
| `spec/protocols/zero-seed.md` | Zero Seed extraction from chat |
| `spec/protocols/ASHC-agentic-self-hosting-compiler.md` | Evidence primitives, spec compilation |
| `spec/protocols/agentese.md` | AGENTESE paths |
| `spec/agents/d-gent.md` | Storage layer |

---

*"The conversation is not an exchange of strings. It is the co-evolution of two belief distributions, witnessed at every step."*

*Last updated: 2025-12-24*
*Version: 4.1b (Analysis Operad + Zero Seed remediation complete)*
