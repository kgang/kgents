# AD-004: Pre-Computed Richness

**Date**: 2025-12-13

> Demo data and QA fixtures SHOULD be pre-computed with real LLM outputs, not synthetic stubs.

---

## Context

Any given LLM task done once is definitionally cheap; when orchestrated and self-compounded, they get expensive. Demo systems that use hardcoded strings miss the soul. The insight: **pre-generate rich data once, hotload forever**.

## Decision

All demo and QA systems use pre-computed LLM outputs:

```python
# Anti-pattern (synthetic stub):
def create_demo_snapshot() -> AgentSnapshot:
    return AgentSnapshot(name="Demo Agent", summary="A placeholder summary")

# Correct (pre-computed richness):
def create_demo_snapshot() -> AgentSnapshot:
    return load_hotdata("fixtures/agent_snapshots/soul_in_deliberation.json")

# The fixture was generated once by running:
#   void.compose.sip(agent, entropy=0.8) → serialize → fixtures/
```

## The Three Truths

1. **Demo kgents ARE kgents**: There is no distinction between "demo" and "real" - demos use the same data paths
2. **LLM-once is cheap**: One LLM call to generate a fixture is negligible; repeated calls compound
3. **Hotload everything**: Any pre-computed output can be swapped at runtime for development velocity

## The HotData Protocol

| Source | Cost | Usage |
|--------|------|-------|
| Pre-computed JSON | Near-zero | Production demos, tests |
| Cached LLM output | One-time | Fixture generation |
| Live LLM | Per-call | Only when freshness required |

## Implementation Pattern

```python
@dataclass
class HotData:
    """Hotloadable pre-computed data with optional refresh."""
    path: Path
    schema: type[T]
    ttl: timedelta | None = None  # None = forever valid

    def load(self) -> T:
        """Load from pre-computed file."""
        return self.schema.from_json(self.path.read_text())

    async def refresh(self, generator: Callable[[], Awaitable[T]]) -> T:
        """Regenerate via LLM if stale."""
        if self._is_fresh():
            return self.load()
        result = await generator()
        self.path.write_text(result.to_json())
        return result
```

## Consequences

- All demo screens use hotloaded fixtures
- Test fixtures are generated by actual agents, not hand-crafted
- `fixtures/` directory contains versioned, pre-computed outputs
- `kg fixture refresh <path>` regenerates stale fixtures via LLM

## Anti-patterns

- Hardcoded placeholder strings in demos
- Hand-crafted test fixtures that don't match real outputs
- Calling LLM repeatedly for the same demo data

*Zen Principle: The first spark costs nothing. The sustained fire requires fuel.*
