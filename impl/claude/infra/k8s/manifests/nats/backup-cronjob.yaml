# NATS JetStream Backup CronJob
#
# Creates daily snapshots of JetStream streams for disaster recovery.
# Stores backups locally (PVC) AND uploads to S3/GCS for cross-region DR.
#
# Backup Strategy:
#   1. Iterate through all JetStream streams
#   2. Create consumer-based snapshot for each stream
#   3. Store as compressed JSON in PVC
#   4. Upload to S3/GCS for cross-region durability
#   5. Clean up backups older than 7 days
#
# Phase 11: External Backup foundation for multi-region DR.
#
# AGENTESE: world.gateway.nats.backup
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nats-backup-pvc
  namespace: kgents-agents
  labels:
    app.kubernetes.io/name: nats-backup
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: kgents
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nats-backup-script
  namespace: kgents-agents
  labels:
    app.kubernetes.io/name: nats-backup
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: kgents
data:
  backup.sh: |
    #!/bin/sh
    set -e

    BACKUP_DIR="/backups"
    TIMESTAMP=$(date +%Y%m%d-%H%M%S)
    BACKUP_PATH="${BACKUP_DIR}/${TIMESTAMP}"
    RETENTION_DAYS=7

    echo "=== NATS JetStream Backup ==="
    echo "Timestamp: ${TIMESTAMP}"
    echo "Backup path: ${BACKUP_PATH}"

    # Create backup directory
    mkdir -p "${BACKUP_PATH}"

    # Export server info
    echo "Exporting server info..."
    nats server info --json > "${BACKUP_PATH}/server-info.json" 2>/dev/null || echo '{"error":"server info unavailable"}' > "${BACKUP_PATH}/server-info.json"

    # Export JetStream account info
    echo "Exporting JetStream account info..."
    nats account info --json > "${BACKUP_PATH}/account-info.json" 2>/dev/null || echo '{"error":"account info unavailable"}' > "${BACKUP_PATH}/account-info.json"

    # List and backup all streams
    echo "Backing up streams..."
    nats stream list --json 2>/dev/null | jq -r '.[] // empty' > "${BACKUP_PATH}/stream-list.json" || echo '[]' > "${BACKUP_PATH}/stream-list.json"

    # For each stream, export configuration and state
    for stream in $(nats stream list -n 2>/dev/null || true); do
      echo "  Backing up stream: ${stream}"
      mkdir -p "${BACKUP_PATH}/streams/${stream}"

      # Export stream config
      nats stream info "${stream}" --json > "${BACKUP_PATH}/streams/${stream}/config.json" 2>/dev/null || true

      # Export stream state (message counts, bytes, etc.)
      nats stream state "${stream}" --json > "${BACKUP_PATH}/streams/${stream}/state.json" 2>/dev/null || true

      # Note: Full message backup requires nats stream backup command
      # which needs direct filesystem access or S3 configuration
      # For now, we capture metadata only
    done

    # Backup consumers
    echo "Backing up consumers..."
    for stream in $(nats stream list -n 2>/dev/null || true); do
      for consumer in $(nats consumer list "${stream}" -n 2>/dev/null || true); do
        echo "  Backing up consumer: ${stream}/${consumer}"
        mkdir -p "${BACKUP_PATH}/consumers/${stream}"
        nats consumer info "${stream}" "${consumer}" --json > "${BACKUP_PATH}/consumers/${stream}/${consumer}.json" 2>/dev/null || true
      done
    done

    # Create compressed archive
    echo "Creating compressed archive..."
    cd "${BACKUP_DIR}"
    tar -czf "${TIMESTAMP}.tar.gz" "${TIMESTAMP}"
    rm -rf "${BACKUP_PATH}"

    # Clean up old backups (retention policy)
    echo "Cleaning up old backups (>${RETENTION_DAYS} days)..."
    find "${BACKUP_DIR}" -name "*.tar.gz" -mtime +${RETENTION_DAYS} -delete

    # List current backups
    echo ""
    echo "Current backups:"
    ls -lh "${BACKUP_DIR}"/*.tar.gz 2>/dev/null || echo "  (none)"

    # Upload to S3/GCS if credentials are configured
    if [ -n "${S3_BUCKET}" ] && [ "${S3_BUCKET}" != "REPLACE_WITH_BUCKET" ]; then
      echo ""
      echo "Uploading to S3: s3://${S3_BUCKET}/${S3_PREFIX:-nats/}"

      # Add aws cli from init container to PATH
      export PATH="/shared/bin:$PATH"

      # Check if aws cli is available
      if command -v aws >/dev/null 2>&1; then
        aws s3 cp "${BACKUP_DIR}/${TIMESTAMP}.tar.gz" \
          "s3://${S3_BUCKET}/${S3_PREFIX:-nats/}${TIMESTAMP}.tar.gz" \
          --only-show-errors

        if [ $? -eq 0 ]; then
          echo "S3 upload successful"

          # Clean up old S3 backups (keep 30 days in S3)
          echo "Listing S3 backups..."
          aws s3 ls "s3://${S3_BUCKET}/${S3_PREFIX:-nats/}" --human-readable
        else
          echo "WARNING: S3 upload failed"
        fi
      else
        echo "WARNING: aws CLI not available, skipping S3 upload"
      fi
    elif [ -n "${GCS_BUCKET}" ]; then
      echo ""
      echo "Uploading to GCS: gs://${GCS_BUCKET}/${GCS_PREFIX:-nats/}"

      # Check if gsutil is available
      if command -v gsutil >/dev/null 2>&1; then
        gsutil cp "${BACKUP_DIR}/${TIMESTAMP}.tar.gz" \
          "gs://${GCS_BUCKET}/${GCS_PREFIX:-nats/}${TIMESTAMP}.tar.gz"

        if [ $? -eq 0 ]; then
          echo "GCS upload successful"
          gsutil ls -lh "gs://${GCS_BUCKET}/${GCS_PREFIX:-nats/}"
        else
          echo "WARNING: GCS upload failed"
        fi
      else
        echo "WARNING: gsutil not available, skipping GCS upload"
      fi
    else
      echo ""
      echo "NOTE: S3/GCS upload skipped (credentials not configured)"
      echo "To enable cross-region backup, create the nats-backup-s3 secret"
    fi

    echo ""
    echo "=== Backup Complete ==="
    echo "Archive: ${BACKUP_DIR}/${TIMESTAMP}.tar.gz"
    echo "Size: $(ls -lh ${BACKUP_DIR}/${TIMESTAMP}.tar.gz 2>/dev/null | awk '{print $5}' || echo 'N/A')"

  restore.sh: |
    #!/bin/sh
    set -e

    BACKUP_DIR="/backups"

    # Usage: restore.sh <backup-filename>
    # Example: restore.sh 20251214-120000.tar.gz

    if [ -z "$1" ]; then
      echo "Usage: restore.sh <backup-filename>"
      echo ""
      echo "Available backups:"
      ls -lh "${BACKUP_DIR}"/*.tar.gz 2>/dev/null || echo "  (none)"
      exit 1
    fi

    BACKUP_FILE="${BACKUP_DIR}/$1"

    if [ ! -f "${BACKUP_FILE}" ]; then
      echo "Error: Backup file not found: ${BACKUP_FILE}"
      exit 1
    fi

    echo "=== NATS JetStream Restore ==="
    echo "Restoring from: ${BACKUP_FILE}"

    # Extract backup
    RESTORE_DIR=$(mktemp -d)
    tar -xzf "${BACKUP_FILE}" -C "${RESTORE_DIR}"
    BACKUP_NAME=$(basename "$1" .tar.gz)

    echo "Extracted to: ${RESTORE_DIR}/${BACKUP_NAME}"

    # Restore streams
    echo "Restoring streams..."
    if [ -d "${RESTORE_DIR}/${BACKUP_NAME}/streams" ]; then
      for stream_dir in "${RESTORE_DIR}/${BACKUP_NAME}/streams"/*; do
        stream=$(basename "${stream_dir}")
        echo "  Restoring stream: ${stream}"

        # Check if stream exists
        if nats stream info "${stream}" > /dev/null 2>&1; then
          echo "    Stream exists, updating config..."
          nats stream edit "${stream}" --config "${stream_dir}/config.json" 2>/dev/null || echo "    Warning: Could not update stream config"
        else
          echo "    Creating stream..."
          nats stream create "${stream}" --config "${stream_dir}/config.json" 2>/dev/null || echo "    Warning: Could not create stream"
        fi
      done
    fi

    # Restore consumers
    echo "Restoring consumers..."
    if [ -d "${RESTORE_DIR}/${BACKUP_NAME}/consumers" ]; then
      for stream_dir in "${RESTORE_DIR}/${BACKUP_NAME}/consumers"/*; do
        stream=$(basename "${stream_dir}")
        for consumer_file in "${stream_dir}"/*.json; do
          consumer=$(basename "${consumer_file}" .json)
          echo "  Restoring consumer: ${stream}/${consumer}"

          # Note: Consumer restoration requires stream to exist
          nats consumer create "${stream}" "${consumer}" --config "${consumer_file}" 2>/dev/null || echo "    Warning: Could not create consumer"
        done
      done
    fi

    # Cleanup
    rm -rf "${RESTORE_DIR}"

    echo ""
    echo "=== Restore Complete ==="
    echo "Note: Message data is NOT restored (metadata only)"
    echo "For full message recovery, use nats stream restore with filesystem backup"
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: nats-backup
  namespace: kgents-agents
  labels:
    app.kubernetes.io/name: nats-backup
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: kgents
spec:
  # Run daily at 2 AM UTC
  schedule: "0 2 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 3
      activeDeadlineSeconds: 600  # 10 minute timeout
      template:
        metadata:
          labels:
            app.kubernetes.io/name: nats-backup
            app.kubernetes.io/component: backup
        spec:
          restartPolicy: OnFailure
          serviceAccountName: default
          # Security context for pod
          securityContext:
            runAsNonRoot: false  # nats-box requires root for some operations
            fsGroup: 1000
          containers:
            - name: backup
              image: natsio/nats-box:0.14.1
              command: ["/bin/sh", "/scripts/backup.sh"]
              env:
                - name: NATS_URL
                  value: "nats://nats.kgents-agents.svc.cluster.local:4222"
                # S3 credentials from secret (optional - enables cross-region backup)
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: nats-backup-s3
                      key: AWS_ACCESS_KEY_ID
                      optional: true
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: nats-backup-s3
                      key: AWS_SECRET_ACCESS_KEY
                      optional: true
                - name: AWS_DEFAULT_REGION
                  valueFrom:
                    secretKeyRef:
                      name: nats-backup-s3
                      key: AWS_DEFAULT_REGION
                      optional: true
                - name: S3_BUCKET
                  valueFrom:
                    secretKeyRef:
                      name: nats-backup-s3
                      key: S3_BUCKET
                      optional: true
                - name: S3_PREFIX
                  valueFrom:
                    secretKeyRef:
                      name: nats-backup-s3
                      key: S3_PREFIX
                      optional: true
              volumeMounts:
                - name: backup-storage
                  mountPath: /backups
                - name: backup-scripts
                  mountPath: /scripts
                - name: shared-tools
                  mountPath: /shared
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 500m
                  memory: 512Mi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
          # Init container to install AWS CLI (if S3 backup is configured)
          initContainers:
            - name: install-aws-cli
              image: alpine:3.19
              command: ["/bin/sh", "-c"]
              args:
                - |
                  # Install AWS CLI via pip in shared volume
                  apk add --no-cache python3 py3-pip
                  mkdir -p /shared/bin
                  pip3 install --target=/shared/lib awscli
                  echo '#!/bin/sh' > /shared/bin/aws
                  echo 'PYTHONPATH=/shared/lib python3 -m awscli "$@"' >> /shared/bin/aws
                  chmod +x /shared/bin/aws
              volumeMounts:
                - name: shared-tools
                  mountPath: /shared
          volumes:
            - name: backup-storage
              persistentVolumeClaim:
                claimName: nats-backup-pvc
            - name: backup-scripts
              configMap:
                name: nats-backup-script
                defaultMode: 0755
            - name: shared-tools
              emptyDir: {}
